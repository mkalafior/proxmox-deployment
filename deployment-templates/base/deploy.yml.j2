---
# Generic container deployment playbook for {{ service_name }}
- name: Deploy {{ service_name }} to Proxmox VE
  hosts: localhost
  connection: local
  gather_facts: true
  vars_files:
    - group_vars/all.yml
  
  tasks:
    - name: Validate environment variables
      assert:
        that:
          - proxmox_host is defined and proxmox_host != ""
          - >
            (proxmox_token_id is defined and proxmox_token_id != "" and 
             proxmox_token_secret is defined and proxmox_token_secret != "") or
            (proxmox_user is defined and proxmox_user != "" and 
             proxmox_password is defined and proxmox_password != "")
        fail_msg: |
          Required Proxmox authentication must be configured.
          Either set API token (TOKEN_ID, TOKEN_SECRET) or username/password (PROXMOX_USER, PROXMOX_PASSWORD).
          API tokens are recommended for automation.

    - name: Debug environment variables
      debug:
        msg: |
          Environment Debug for {{ service_name }}:
          - PROXMOX_HOST: {{ lookup('env', 'PROXMOX_HOST') | default('not set') }}
          - PROXMOX_USER: {{ lookup('env', 'PROXMOX_USER') | default('not set') }}
          - PROXMOX_PASSWORD: {{ 'SET' if lookup('env', 'PROXMOX_PASSWORD') != '' else 'not set' }}
          - TOKEN_ID: {{ lookup('env', 'TOKEN_ID') | default('not set') }}
          - TOKEN_SECRET: {{ 'SET' if lookup('env', 'TOKEN_SECRET') != '' else 'not set' }}
          
          Service Configuration:
          - Service Name: {{ service_name }}
          - VM ID: {{ vm_id }}
          - VM Name: {{ vm_name }}
          - App Port: {{ app_port }}

    - name: Display authentication method
      debug:
        msg: |
          Using {{ 'API Token' if (proxmox_token_id != '' and proxmox_token_secret != '') else 'Username/Password' }} authentication
          Token ID: {{ proxmox_token_id if (proxmox_token_id != '') else 'Not configured' }}
          User: {{ proxmox_user if (proxmox_user != '') else 'Not configured' }}

    - name: Check for SSH public key
      stat:
        path: "{{ ssh_public_key_path }}"
      register: ssh_key_stat

    - name: Generate dedicated Proxmox SSH key if it doesn't exist
      openssh_keypair:
        path: "{{ ssh_public_key_path | replace('.pub', '') }}"
        type: ed25519
        comment: "proxmox-{{ vm_name }}-{{ ansible_date_time.date }}"
      when: not ssh_key_stat.stat.exists

    - name: Read SSH public key
      slurp:
        src: "{{ ssh_public_key_path }}"
      register: ssh_public_key_content
      when: ssh_public_key_path is defined

    - name: Install Ansible collections from requirements.yml (idempotent)
      command: ansible-galaxy collection install -r requirements.yml --force
      args:
        chdir: "{{ playbook_dir }}"
      changed_when: false
      delegate_to: localhost
      run_once: true
      become: false

    - name: Create Proxmox container via curl command
      shell: |
        curl -k -X POST \
          -H "Authorization: PVEAPIToken={{ proxmox_token_id }}={{ proxmox_token_secret }}" \
          -H "Content-Type: application/x-www-form-urlencoded" \
          -d "vmid={{ vm_id }}&unprivileged=1&features=nesting%3D1&password={{ (lookup('password', '/tmp/vm_root_password chars=ascii_letters,digits length=16')) | urlencode }}{% if ssh_public_key_content is defined %}&ssh-public-keys={{ ssh_public_key_content.content | b64decode | trim | urlencode }}{% endif %}&ostemplate={{ vm_os_template | urlencode }}&rootfs={{ (vm_storage ~ ':' ~ vm_disk_size) | urlencode }}&cores={{ vm_cores }}&memory={{ vm_memory }}&swap={{ vm_swap }}&net0={{ ('name=eth0,bridge=' ~ vm_network_bridge ~ ',firewall=1,ip=dhcp') | urlencode }}" \
          "https://{{ proxmox_host }}:8006/api2/json/nodes/{{ proxmox_node }}/lxc"
      register: proxmox_vm
      failed_when: false

    - name: Debug container creation response
      debug:
        var: proxmox_vm
        verbosity: 1

    - name: Check if container creation was successful
      fail:
        msg: |
          Container creation failed!

          API Response: {{ proxmox_vm.stdout | default('No response') }}
          Error Details: {{ proxmox_vm.stderr | default('No error details') }}
          Return Code: {{ proxmox_vm.rc | default('Unknown') }}

          Troubleshooting Tips:
          1. Check if OS template exists: {{ vm_os_template }}
          2. Verify Proxmox node name: {{ proxmox_node }}
          3. Ensure storage '{{ vm_storage }}' exists and has space
          4. Check API token permissions for VM creation
          5. Verify VM ID {{ vm_id }} is not already in use

          Run the debug script: ./tools/proxmox-debug.sh
      when: proxmox_vm.rc != 0 or (proxmox_vm.stdout | default('')) == '' or ((proxmox_vm.stdout | from_json).data is not defined) or ((proxmox_vm.stdout | from_json).data is none)

    - name: Extract UPID from successful container creation
      set_fact:
        container_upid: "{{ (proxmox_vm.stdout | from_json).data }}"
      when: proxmox_vm.rc == 0 and (proxmox_vm.stdout | from_json).data is defined
      


    - name: Start the container via direct API call (idempotent)
      uri:
        url: "https://{{ proxmox_host }}:8006/api2/json/nodes/{{ proxmox_node }}/lxc/{{ vm_id }}/status/start"
        method: POST
        headers:
          Authorization: "PVEAPIToken={{ proxmox_token_id }}={{ proxmox_token_secret }}"
        validate_certs: "{{ proxmox_api_validate_certs }}"
        status_code: [200, 500]
        timeout: 60
      register: start_result
      failed_when: false
      changed_when: "start_result.status == 200"
    
    - name: Define backoff delays for slow PVE clusters
      set_fact:
        pxd_backoff_delays: [20, 30, 30, 60, 60]

    - name: Try IP discovery with progressive backoff - include task file per attempt
      include_tasks: templates/ip_discovery_tasks.yml
      loop: "{{ pxd_backoff_delays }}"
      loop_control:
        loop_var: wait_seconds
      when: (container_ip | default('')) == ''

    - name: Verify container is running before IP discovery
      uri:
        url: "https://{{ proxmox_host }}:8006/api2/json/nodes/{{ proxmox_node }}/lxc/{{ vm_id }}/status/current"
        method: GET
        headers:
          Authorization: "PVEAPIToken={{ proxmox_token_id }}={{ proxmox_token_secret }}"
        validate_certs: "{{ proxmox_api_validate_certs }}"
        timeout: 30
        return_content: yes
        status_code: [200]
      register: container_status_result
      when: proxmox_token_id != '' and proxmox_token_secret != ''

    - name: Debug container status
      debug:
        msg: |
          Container Status Debug:
          - Status: {{ container_status_result.json.data.status | default('unknown') }}
          - Uptime: {{ container_status_result.json.data.uptime | default('0') }}
          - VMID: {{ container_status_result.json.data.vmid | default('unknown') }}
      when: container_status_result is defined

    # Old retry removed in favor of progressive backoff above

    - name: Debug interfaces API response
      debug:
        msg: |
          Interfaces API Debug:
          - Status Code: {{ container_interfaces_result.status | default('not attempted') }}
          - Response: {{ container_interfaces_result.json | default('no response') }}
          - Data: {{ container_interfaces_result.json.data | default('no data') }}
      when: container_interfaces_result is defined

    - name: Extract container IP
      set_fact:
        container_ip: "{{ (eth0_interface.inet | default('')) | regex_replace('/.*$', '') }}"
      vars:
        eth0_interface: "{{ container_interfaces_result.json.data | selectattr('name', 'equalto', 'eth0') | first }}"
      when:
        - container_interfaces_result.json is defined
        - container_interfaces_result.json.data is defined

    - name: Fallback - get container IP via pct exec
      shell: |
        /usr/sbin/pct exec {{ vm_id }} -- sh -lc "ip -o -4 addr show dev eth0 | awk '{print \\ $4}' | head -n1"
      register: pct_ip_result
      changed_when: false
      ignore_errors: true
      delegate_to: "{{ proxmox_host }}"
      environment:
        PATH: "/usr/sbin:/usr/bin:/bin:/sbin"
      when: container_ip is not defined or (container_ip | default('')) == ''

    - name: Use pct exec result if available
      set_fact:
        container_ip: "{{ pct_ip_result.stdout | default('') | trim | regex_replace('/.*$', '') }}"
      when: pct_ip_result is defined and (pct_ip_result.stdout | default('') | trim) != ''

    - name: Fail deployment if IP discovery failed
      fail:
        msg: |
          ❌ DEPLOYMENT FAILED: Could not retrieve container IP address automatically.
          
          The container was created but IP discovery failed. This prevents proper deployment.
          
          🔧 To fix this issue:
          1. Check Proxmox web interface: https://{{ proxmox_host }}:8006
          2. Navigate to node {{ proxmox_node }} -> CT {{ vm_id }} -> Summary
          3. Verify the container has an IP address
          4. If container has IP, this is an API timing issue - retry deployment
          5. If container has no IP, check network configuration
          
          📊 Debug Information:
          - Container ID: {{ vm_id }}
          - Node: {{ proxmox_node }}
          - Interfaces API Status: {{ container_interfaces_result.status | default('not attempted') }}
          - API Response: {{ container_interfaces_result.json.data | default('no data') }}
          
          💡 You can retry the deployment after the container gets an IP address.
      when: container_ip is not defined or (container_ip | default('')) == ''

    - name: Debug container info
      debug:
        msg: |
          Container created successfully for {{ service_name }}!
          VMID: {{ vm_id }}
          Name: {{ vm_name }}
          Node: {{ proxmox_node }}
          IP: {{ container_ip }}

    - name: Wait for SSH to become available with key
      wait_for:
        host: "{{ container_ip }}"
        port: 22
        delay: 5
        timeout: 30
        state: started
      vars:
        ansible_python_interpreter: "{{ ansible_playbook_python }}"
      when: container_ip is defined

    - name: Add container to dynamic inventory
      add_host:
        name: "{{ container_ip }}"
        groups: proxmox_containers
        ansible_host: "{{ container_ip }}"
        ansible_user: root
        ansible_ssh_private_key_file: "{{ ssh_public_key_path | replace('.pub', '') }}"
        vm_id: "{{ vm_id }}"
      when: container_ip is defined

    # Note: We no longer persist IPs locally; use DNS/Proxmox API via CLI

- name: Configure container and deploy {{ service_name }} application
  hosts: proxmox_containers
  become: true
  vars_files:
    - group_vars/all.yml
  
  tasks:
    - name: Wait for system to be ready
      wait_for_connection:
        timeout: 300

    - name: Test internet connectivity
      uri:
        url: http://archive.ubuntu.com
        timeout: 5
      register: internet_test
      ignore_errors: true

    - name: Skip package installation if no internet
      debug:
        msg: "No internet access - skipping package installation. Run fix-proxmox-networking.sh on Proxmox host."
      when: internet_test.failed

    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600
      when: not internet_test.failed

    - name: Install system packages
      apt:
        name:
          - curl
          - wget
          - git
          - unzip
          - ufw
          - build-essential  # For native modules if needed
          - qemu-guest-agent  # For IP address discovery
        state: present
      when: not internet_test.failed

    # (collections are installed in the localhost phase above)
  
    - name: Configure firewall
      ufw:
        rule: allow
        port: "{{ item }}"
      loop: "{{ allowed_ports }}"

    - name: Enable firewall
      ufw:
        state: enabled

    # SERVICE-SPECIFIC INJECTION POINT: Runtime Installation
    {% if service_runtime_install is defined and service_runtime_install %}
    {% include 'service-parts/runtime_install.yml.j2' %}
    {% endif %}

    - name: Create application user
      user:
        name: "{{ app_user }}"
        system: yes
        shell: /bin/bash
        home: "{{ app_dir }}"
        create_home: yes

    - name: Create application directory
      file:
        path: "{{ app_dir }}"
        state: directory
        owner: "{{ app_user }}"
        group: "{{ app_user }}"
        mode: '0755'

    - name: Copy application files using tar
      block:
        - name: Create tar archive of application
          shell: |
            cd {{ local_app_path }}
            # Check if .deployignore exists and build exclude options
            EXCLUDE_OPTS=""
            if [ -f .deployignore ]; then
              # Read .deployignore and convert to tar exclude options
              while IFS= read -r line || [ -n "$line" ]; do
                # Skip empty lines and comments
                if [[ -n "$line" && ! "$line" =~ ^[[:space:]]*# ]]; then
                  # Remove leading/trailing whitespace
                  line=$(echo "$line" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
                  if [[ -n "$line" ]]; then
                    EXCLUDE_OPTS="$EXCLUDE_OPTS --exclude='$line'"
                  fi
                fi
              done < .deployignore
            else
              # Default exclusions if no .deployignore file
              EXCLUDE_OPTS="--exclude='node_modules' --exclude='.git' --exclude='deployment' --exclude='deployments' --exclude='*.log' --exclude='.env'"
            fi
            
            # Create tar with dynamic exclusions
            eval "tar $EXCLUDE_OPTS -czf /tmp/{{ service_name }}-app.tar.gz ."
          delegate_to: localhost
          become: false

        - name: Copy tar archive to container
          copy:
            src: "/tmp/{{ service_name }}-app.tar.gz"
            dest: "/tmp/{{ service_name }}-app.tar.gz"
            mode: '0644'

        - name: Extract application files
          unarchive:
            src: "/tmp/{{ service_name }}-app.tar.gz"
            dest: "{{ app_dir }}"
            remote_src: yes
            owner: "{{ app_user }}"
            group: "{{ app_user }}"

        - name: Clean up tar files on remote container
          file:
            path: "/tmp/{{ service_name }}-app.tar.gz"
            state: absent

        - name: Clean up tar files on local machine
          file:
            path: "/tmp/{{ service_name }}-app.tar.gz"
            state: absent
          delegate_to: localhost
          become: false

      when: service_type != 'database'

    - name: Set ownership of application files
      file:
        path: "{{ app_dir }}"
        owner: "{{ app_user }}"
        group: "{{ app_user }}"
        recurse: yes
      when: service_type != 'database'

    # SERVICE-SPECIFIC INJECTION POINT: Dependency Installation
    {% if service_dependency_install is defined and service_dependency_install %}
    {% include 'service-parts/dependency_install.yml.j2' %}
    {% endif %}

    # SERVICE-SPECIFIC INJECTION POINT: Build Tasks
    {% if service_build_tasks is defined and service_build_tasks %}
    {% include 'service-parts/build_tasks.yml.j2' %}
    {% endif %}

    - name: Detect local custom deployment script
      stat:
        path: "{{ playbook_dir }}/scripts/custom_script.sh"
      register: local_custom_script
      delegate_to: localhost
      become: false

    - name: Upload custom deployment script to container
      copy:
        src: "{{ playbook_dir }}/scripts/custom_script.sh"
        dest: "/opt/custom_script.sh"
        mode: '0755'
        owner: root
        group: root
      when: local_custom_script.stat.exists

    - name: Run custom deployment script (service-specific hook)
      shell: "/opt/custom_script.sh"
      args:
        chdir: "{{ app_dir }}"
      become_user: "{{ app_user }}"
      environment:
        APP_DIR: "{{ app_dir }}"
        SERVICE_TYPE: "{{ service_type | default('') }}"
        NODEJS_RUNTIME: "{{ nodejs_runtime | default('') }}"
        APP_PORT: "{{ app_port | string }}"
        SERVICE_NAME: "{{ service_name }}"
      register: custom_script_result
      changed_when: false
      failed_when: false
      when: local_custom_script.stat.exists

    - name: Show custom script output
      debug:
        var: custom_script_result.stdout_lines
      when: local_custom_script.stat.exists

    - name: Create environment file
      template:
        src: env.j2
        dest: "{{ app_dir }}/.env"
        owner: "{{ app_user }}"
        group: "{{ app_user }}"
        mode: '0600'
      when: service_type != 'database'

    # SERVICE-SPECIFIC INJECTION POINT: Systemd Service
    {% if service_systemd_service is defined and service_systemd_service %}
    - name: Create systemd service file
      template:
        src: "{{ app_service_name }}.service.j2"
        dest: "/etc/systemd/system/{{ app_service_name }}.service"
        mode: '0644'
      notify: reload systemd
      when: service_type != 'database'

    - name: Enable and start application service
      systemd:
        name: "{{ app_service_name }}"
        enabled: yes
        state: started
        daemon_reload: yes
      when: service_type != 'database'
    {% endif %}

    - name: Wait for service to be running
      pause:
        seconds: 5
      when: service_type != 'database'

    - name: Copy DNS authentication key
      template:
        src: bind-key.conf.j2
        dest: /etc/bind-key.conf
        mode: '0600'
        owner: root
        group: root

    - name: Install netcat for DNS connectivity testing
      apt:
        name: netcat-openbsd
        state: present

    - name: Copy DNS registration script
      template:
        src: dns-register.sh.j2
        dest: /opt/dns-register.sh
        mode: '0755'
        owner: root
        group: root

    - name: Test DNS registration script
      command: /opt/dns-register.sh test
      register: dns_test_result
      ignore_errors: true

    - name: Display DNS test result
      debug:
        msg: |
          DNS Test Result for {{ service_name }}:
          rc: {{ dns_test_result.rc | default('n/a') }}
          stdout: {{ dns_test_result.stdout | default('') }}
          stderr: {{ dns_test_result.stderr | default('') }}

    - name: Create DNS registration service
      template:
        src: dns-register.service.j2
        dest: /etc/systemd/system/dns-register.service
        mode: '0644'
      notify: reload systemd

    - name: Enable and start DNS registration service
      systemd:
        name: dns-register
        enabled: yes
        state: started
        daemon_reload: yes

    - name: Wait for DNS registration to complete
      pause:
        seconds: 3

    - name: Test hostname resolution
      shell: nslookup {{ service_hostname }}.{{ dns_domain }} {{ dns_server }}
      register: dns_resolution_test
      ignore_errors: true

    - name: Display DNS resolution result
      debug:
        msg: |
          DNS Resolution Test for {{ service_name }}:
          rc: {{ dns_resolution_test.rc | default('n/a') }}
          stdout: {{ dns_resolution_test.stdout | default('') }}
          stderr: {{ dns_resolution_test.stderr | default('') }}

    # Cloudflare Tunnel Configuration (if enabled)
    - name: Check if Cloudflare domain is configured
      set_fact:
        cloudflare_enabled: "{{ cloudflare_domain is defined and cloudflare_domain != '' }}"
      
    - name: Configure Cloudflare tunnel routing
      block:
        - name: Get tunnel UUID
          shell: cloudflared tunnel list | grep 'proxmox-main' | awk '{print $1}'
          register: tunnel_uuid_result
          delegate_to: "{{ proxmox_host }}"
          
        - name: Set tunnel UUID fact
          set_fact:
            tunnel_uuid: "{{ tunnel_uuid_result.stdout.strip() }}"
            
        - name: Backup current tunnel configuration
          copy:
            src: /etc/cloudflared/config.yml
            dest: "/etc/cloudflared/config.yml.backup.{{ ansible_date_time.date }}_{{ ansible_date_time.hour }}{{ ansible_date_time.minute }}{{ ansible_date_time.second }}"
            remote_src: yes
          delegate_to: "{{ proxmox_host }}"
          
        - name: Generate new tunnel configuration
          template:
            src: cloudflare-tunnel-config.yml.j2
            dest: /tmp/new_tunnel_config.yml
          delegate_to: localhost
          
        - name: Upload new tunnel configuration
          copy:
            src: /tmp/new_tunnel_config.yml
            dest: /etc/cloudflared/config.yml
          delegate_to: "{{ proxmox_host }}"
          
        - name: Clean up temporary config file
          file:
            path: /tmp/new_tunnel_config.yml
            state: absent
          delegate_to: localhost
          
        - name: Restart cloudflared service
          systemd:
            name: cloudflared
            state: restarted
          delegate_to: "{{ proxmox_host }}"
          
        - name: Wait for cloudflared to restart
          pause:
            seconds: 5
            
        - name: Create DNS route for tunnel
          shell: cloudflared tunnel route dns proxmox-main {{ app_subdomain }}.{{ cloudflare_domain }}
          delegate_to: "{{ proxmox_host }}"
          ignore_errors: true
            
        - name: Verify cloudflared service status
          systemd:
            name: cloudflared
          register: cloudflared_status
          delegate_to: "{{ proxmox_host }}"
          
        - name: Display Cloudflare tunnel status
          debug:
            msg: |
              Cloudflare Tunnel Status:
              Service: {{ cloudflared_status.status.ActiveState }}
              Public URL: https://{{ app_subdomain }}.{{ cloudflare_domain }}
              
      when: cloudflare_enabled | bool

    # SERVICE STATUS CHECKS (only if systemd service is enabled)
    {% if service_systemd_service is defined and service_systemd_service %}
    - name: Check service status
      systemd:
        name: "{{ app_service_name }}"
      register: service_status
      when: service_type != 'database'

    - name: Display service status
      debug:
        msg: |
          {{ service_name }} Service Status: {{ service_status.status.ActiveState }}
          Service is {{ 'running' if service_status.status.ActiveState == 'active' else 'not running' }}
      when: service_type != 'database'

    - name: Test application endpoint
      uri:
        url: "http://{{ ansible_host }}:{{ app_port }}{{ health_check_path | default('/health') }}"
        method: GET
        timeout: 10
      register: health_check
      ignore_errors: yes
      when: service_type != 'database'

    - name: Display health check result
      debug:
        msg: |
          {{ service_name }} Health check status: {{ health_check.status | default('unknown') }}
          Endpoint: http://{{ ansible_host }}:{{ app_port }}{{ health_check_path | default('/health') }}
      when: service_type != 'database'

    - name: Show recent logs
      command: journalctl -u {{ app_service_name }} --lines=10 --no-pager
      register: service_logs
      changed_when: false
      when: service_type != 'database'

    - name: Display recent logs
      debug:
        var: service_logs.stdout_lines
      when: service_type != 'database'
    {% endif %}
    

  handlers:
    - name: reload systemd
      systemd:
        daemon_reload: yes
    - name: restart tor
      systemd:
        name: tor
        state: restarted
    - name: restart privoxy
      systemd:
        name: privoxy
        state: restarted
